{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import rasterio\n",
    "import urllib.request\n",
    "import shapely\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pylab as plt\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from sentinel2download.overlap import Sentinel2Overlap\n",
    "\n",
    "from utils import crop_raster, merge_tiles, stitch_tiles, get_tiles\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = os.getenv('START_DATE', '2016-05-01')\n",
    "END_DATE = os.getenv('END_DATE', '2023-06-30')\n",
    "AOI = os.getenv(\n",
    "    'AOI', 'POLYGON ((-85.299088 40.339368, -85.332047 40.241477, -85.134979 40.229427, -85.157639 40.34146, -85.299088 40.339368))')\n",
    "# AOI = os.getenv('AOI', 'MULTIPOLYGON (((-110.49367408906883 39.1005200348037, -110.20673076923077 39.1005200348037, -110.16573886639677 38.41732165423689, -110.43901821862349 38.41732165423689, -110.49367408906883 39.1005200348037)))')\n",
    "\n",
    "SATELLITE_CACHE_FOLDER = os.getenv('SENTINEL2_CACHE', os.path.join(\n",
    "    \"code\", \"sentinel_cache\", \"landcover_dataset\"))\n",
    "OUTPUT_FOLDER = os.getenv(\n",
    "    'OUTPUT_FOLDER', os.path.join(\"code\", \"results\", \"landcover\"))\n",
    "\n",
    "landcovers_grid = gpd.read_file('landcovers_grid.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI='MULTIPOLYGON (((14.66114877031896 48.58274154385973, 14.72399509478079 48.58655041200893, 14.72617159086605 48.53050563781352, 14.6589722742337 48.49513757642807, 14.66114877031896 48.58274154385973)))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = shapely.wkt.loads(AOI)\n",
    "aoi_filename = f\"{time.time()}_aoi.geojson\"\n",
    "gpd.GeoDataFrame(\n",
    "    gpd.GeoSeries([polygon]),\n",
    "    columns=[\"geometry\"]).to_file(aoi_filename, driver=\"GeoJSON\")\n",
    "\n",
    "aoi = gpd.read_file(aoi_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2overlap = Sentinel2Overlap(aoi_path=aoi_filename)\n",
    "overlap_tiles = landcovers_grid[landcovers_grid.intersects(polygon)].name.values.tolist()\n",
    "\n",
    "start_year = int(START_DATE.split(\"-\")[0])\n",
    "end_year = int(END_DATE.split(\"-\")[0])\n",
    "\n",
    "date_range = range(2017, 2022)\n",
    "\n",
    "if end_year in date_range:\n",
    "    year = end_year\n",
    "elif start_year in date_range:\n",
    "    year = start_year\n",
    "else:\n",
    "    year = max(list(date_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/input/SENTINEL2_CACHE/landcover_dataset/32T_20190101-20200101.tif',\n",
       " '/input/SENTINEL2_CACHE/landcover_dataset/33T_20190101-20200101.tif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "landcover_dataset_path = os.path.join(\n",
    "    SATELLITE_CACHE_FOLDER, \"landcover_dataset\")\n",
    "os.makedirs(landcover_dataset_path, exist_ok=True)\n",
    "\n",
    "for tile_i in overlap_tiles:\n",
    "    tile_i = tile_i if len(tile_i) < 4 else tile_i[:3]\n",
    "    tile_url = f\"https://lulctimeseries.blob.core.windows.net/lulctimeseriespublic/lc{year}/{tile_i}_{year}0101-{year+1}0101.tif\"\n",
    "    path = os.path.join(landcover_dataset_path, os.path.basename(tile_url))\n",
    "    if not os.path.exists(path):\n",
    "        urllib.request.urlretrieve(tile_url, path)\n",
    "    files.append(path)\n",
    "\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    1: \"Water\",\n",
    "    2: \"Trees\",\n",
    "    4: \"Flooded vegetation\",\n",
    "    5: \"Crops\",\n",
    "    7: \"Built Area\",\n",
    "    8: \"Bare ground\",\n",
    "    9: \"Snow/Ice\",\n",
    "    10: \"Clouds\",\n",
    "    11: \"Rangeland\"\n",
    "}\n",
    "\n",
    "class_colors = {\n",
    "    1: \"65,155,223\",\n",
    "    2: \"57,125,73\",\n",
    "    4: \"122,135,198\",\n",
    "    5: \"228,150,53\",\n",
    "    7: \"196,50,27\",\n",
    "    8: \"165,155,143\",\n",
    "    9: \"168,235,255\",\n",
    "    10: \"97,97,97\",\n",
    "    11: \"227,226,195\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start merging to /input/SENTINEL2_CACHE/aoi_raster.tif\n",
      "Copying color table from /input/SENTINEL2_CACHE/landcover_dataset/32T_20190101-20200101.tif to new file.\n",
      "Creating output file that is 102679P x 89839L.\n",
      "Processing /input/SENTINEL2_CACHE/landcover_dataset/32T_20190101-20200101.tif [1/2] : 0Using internal nodata values (e.g. 0) for image /input/SENTINEL2_CACHE/landcover_dataset/32T_20190101-20200101.tif.\n",
      "Copying nodata values from source /input/SENTINEL2_CACHE/landcover_dataset/32T_20190101-20200101.tif to destination /input/SENTINEL2_CACHE/aoi_raster.tif.\n",
      "...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing /input/SENTINEL2_CACHE/landcover_dataset/33T_20190101-20200101.tif [2/2] : 0Using internal nodata values (e.g. 0) for image /input/SENTINEL2_CACHE/landcover_dataset/33T_20190101-20200101.tif.\n",
      "...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "300.51434230804443 seconds for merging 2 images in to /input/SENTINEL2_CACHE/aoi_raster.tif\n"
     ]
    }
   ],
   "source": [
    "if len(files) > 1:\n",
    "    try:\n",
    "        raster_path = merge_tiles(\n",
    "            files, os.path.join(SATELLITE_CACHE_FOLDER, \"aoi_raster.tif\"))\n",
    "    except Exception:\n",
    "        raster_path = stitch_tiles(\n",
    "            files, os.path.join(SATELLITE_CACHE_FOLDER, \"aoi_raster.tif\"))\n",
    "else:\n",
    "    raster_path = files[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_NotSupported in driver GTiff does not support creation option START_DATE\n",
      "WARNING:rasterio._env:CPLE_NotSupported in driver GTiff does not support creation option END_DATE\n",
      "WARNING:rasterio._env:CPLE_NotSupported in driver GTiff does not support creation option NAME\n"
     ]
    }
   ],
   "source": [
    "raster_path = crop_raster(\n",
    "    raster_path,\n",
    "    aoi_filename,\n",
    "    raster_path.replace(\".tif\", \"_crop.tif\"),\n",
    "    additional_meta={\n",
    "        \"START_DATE\": f\"{year}-01-01\",\n",
    "        \"END_DATE\": f\"{year+1}-01-01\",\n",
    "        \"NAME\": \"Landcover classification\"})\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    img = src.read(1)\n",
    "    mask = src.read_masks(1)\n",
    "    profile = src.profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"color\": \"65,155,223\", \"name\": \"Water\", \"area\": 0.1119}, {\"color\": \"57,125,73\", \"name\": \"Trees\", \"area\": 0.2864}, {\"color\": \"122,135,198\", \"name\": \"Flooded vegetation\", \"area\": 48.6103}, {\"color\": \"228,150,53\", \"name\": \"Crops\", \"area\": 0.0}, {\"color\": \"196,50,27\", \"name\": \"Built Area\", \"area\": 0.0}, {\"color\": \"165,155,143\", \"name\": \"Bare ground\", \"area\": 0.0}, {\"color\": \"168,235,255\", \"name\": \"Snow/Ice\", \"area\": 0.0}, {\"color\": \"97,97,97\", \"name\": \"Clouds\", \"area\": 0.004}, {\"color\": \"227,226,195\", \"name\": \"Rangeland\", \"area\": 0.3059}]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_names)\n",
    "arr = np.array(range(0, NUM_CLASSES)) / NUM_CLASSES\n",
    "colors = plt.cm.jet(arr)\n",
    "colors[0] = (0, 0, 0, 1)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for label, name in enumerate(class_names):\n",
    "    class_area = len(img[img == label]) / 10 ** 4\n",
    "    # convert list of float values into string representing color\n",
    "    if class_area != 0:\n",
    "        labels.append({\n",
    "            \"color\": class_colors[name],\n",
    "            \"name\": class_names[name],\n",
    "            \"area\": class_area\n",
    "        })\n",
    "    else:\n",
    "        labels.append({\n",
    "            \"color\": class_colors[name],\n",
    "            \"name\": \"Other\" if name not in class_names.keys() else class_names[name],\n",
    "            \"area\": 0.0\n",
    "        })\n",
    "labels = json.dumps(labels)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "NUM_CLASSES = 11\n",
    "nodata = 0\n",
    "mask = mask.astype(bool)\n",
    "scaled = img.astype(np.float32) / NUM_CLASSES\n",
    "scaled = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "for label, color in class_colors.items():\n",
    "    color_mask = img == label\n",
    "    scaled[color_mask] = np.array(color.split(','), dtype=np.uint8)\n",
    "    \n",
    "scaled[mask[:, :, np.newaxis] & (scaled == 0)] += 1\n",
    "scaled = np.clip(scaled, 0, 255).astype(np.uint8)\n",
    "# Set pixels with invalid pixels to new nodata value\n",
    "scaled[~mask] = nodata\n",
    "# # Set pixels with background class(0) to new nodata value\n",
    "scaled[img == 0] = nodata\n",
    "\n",
    "profile.update(\n",
    "    count=3,\n",
    "    nodata=nodata,\n",
    "    compress='lzw'\n",
    ")\n",
    "colored_tif = os.path.join(OUTPUT_FOLDER, f\"{START_DATE}_{END_DATE}.tif\")\n",
    "\n",
    "with rasterio.open(colored_tif, 'w', **profile) as dst:\n",
    "    dst.update_tags(start_date=START_DATE,\n",
    "                    end_date=END_DATE,\n",
    "                    labels=labels,\n",
    "                    name=\"Landcover\")\n",
    "    for i in range(scaled.shape[-1]):\n",
    "        dst.write(scaled[:, :, i], indexes=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(raster_path)\n",
    "os.remove(aoi_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
